{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37757345",
   "metadata": {},
   "source": [
    "# Hit Song Predictor: A Logistic Regression Approach\n",
    "\n",
    "## Project Overview\n",
    "This project uses logistic regression to predict whether a song will be a 'hit' based on audio features like danceability, energy, valence, and tempo. The model analyzes patterns in successful tracks to identify what makes a song popular.\n",
    "\n",
    "**Key Skills Demonstrated:**\n",
    "- Binary classification with logistic regression\n",
    "- Feature engineering and selection\n",
    "- Handling imbalanced datasets\n",
    "- Model evaluation and interpretation\n",
    "- Data visualization for music analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72470d34",
   "metadata": {},
   "source": [
    "### Import Necessary Tools & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248620fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70395d84",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eedb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"songs_normalize.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9bb4c",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab7019",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ebd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nBasic Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe23944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what makes a 'hit' - songs with popularity > 70\n",
    "# Adjusted this threshold based on dataset\n",
    "popularity_threshold = df['popularity'].quantile(0.75)\n",
    "df['is_a_hit'] = (df['popularity'] > popularity_threshold).astype(int)\n",
    "\n",
    "print(f\"Popularity threshold for 'hit': {popularity_threshold}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['is_a_hit'].value_counts())\n",
    "print(f\"\\nHit rate: {df['is_a_hit'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ea8f1",
   "metadata": {},
   "source": [
    "### Visualize audio feature distributions for hits vs non-hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e771d",
   "metadata": {},
   "source": [
    "#### The Visualization shows\n",
    "Expected Strong Features:\n",
    "\n",
    "- Danceability ⭐⭐⭐\n",
    "- Energy ⭐⭐⭐\n",
    "- Valence ⭐⭐\n",
    "\n",
    "Expected Weak Features:\n",
    "\n",
    "- Tempo, Acousticness, Instrumentalness, Liveness, Speechiness, and Loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = ['danceability', 'energy', 'valence', 'tempo', 'acousticness', \n",
    "                  'instrumentalness', 'liveness', 'speechiness', 'loudness']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(audio_features):\n",
    "    axes[idx].hist(df[df['is_a_hit']==1][feature], alpha=0.5, label='Hit', bins=30, color='green')\n",
    "    axes[idx].hist(df[df['is_a_hit']==0][feature], alpha=0.5, label='Not a Hit', bins=30, color='red')\n",
    "    axes[idx].set_title(f'{feature.capitalize()} Distribution')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b03f9",
   "metadata": {},
   "source": [
    "### Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e599170",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df[audio_features + ['is_a_hit']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', square=True, linewidths=1)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1720781",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "The correlation heatmap reveals an that no individual audio feature shows string correlation with hit status (as expected since music is subjective, and there are many factors that go into having a hit, such as marketing, artist's popularity, timing, and cultureal context). The strongest correlations are:\n",
    "\n",
    "- Danceability: -0.02\n",
    "- Energy: -0.07  \n",
    "- Valence: -0.09\n",
    "- Acousticness: 0.07\n",
    "- All other features: ≈ 0.00\n",
    "\n",
    "### My Solution: Feature Engineering\n",
    "\n",
    "Since individual features lack predictive power, I will create interaction features that combine multiple attributes:\n",
    "\n",
    "1. **Energy × Danceability**: Captures the \"party factor\" - songs that are both energetic & danceable\n",
    "2. **Valence × Energy**: Represents upbeat, positive vibes\n",
    "3. **Mood Score**: Average of valence and energy for overall emotional tone\n",
    "4. **Normalized Tempo**: Standardized BPM for better model scaling\n",
    "\n",
    "**Hypothesis**: These engineered features will capture the non-linear relationships and feature combinations that differentiate hits from non-hits, where individual features alone cannot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e4f00",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee369d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['energy_danceability'] = df['energy'] * df['danceability']\n",
    "df['valence_energy'] = df['valence'] * df['energy']\n",
    "\n",
    "# Normalize tempo (convert BPM to a 0-1 scale)\n",
    "df['tempo_normalized'] = (df['tempo'] - df['tempo'].min()) / (df['tempo'].max() - df['tempo'].min())\n",
    "\n",
    "# Create a 'mood' feature combining valence and energy\n",
    "df['mood_score'] = (df['valence'] + df['energy']) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291c4ec",
   "metadata": {},
   "source": [
    "### Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "feature_columns = ['danceability', 'energy', 'valence', 'tempo_normalized', \n",
    "                   'acousticness', 'instrumentalness', 'liveness', 'speechiness', \n",
    "                   'loudness', 'energy_danceability', 'valence_energy', 'mood_score']\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['is_a_hit']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                      random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df275a87",
   "metadata": {},
   "source": [
    "### Standardizing Features for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94032d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier interpretation\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde00381",
   "metadata": {},
   "source": [
    "### Train Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "baseline_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "baseline_score = baseline_model.score(X_test_scaled, y_test)\n",
    "print(f\"Baseline Model Accuracy: {baseline_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b308d",
   "metadata": {},
   "source": [
    "### Hyperparameter Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GridSearchCV (Test all possible combinations of settings and pick the best one)\n",
    "param_grid = {\n",
    "    # How much the model will trust the data: \n",
    "        # 0.001 [Don't Trust data too much] \n",
    "        # 100   [Trust the data and get every detail]\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "\n",
    "    # How to simplify the model:\n",
    "        # L1: turn off uselss features completely\n",
    "        # L2: Make all features contribute a little bit \n",
    "    'penalty': ['l1', 'l2'], \n",
    "\n",
    "    #Which algorithm trains the model?\n",
    "        # liblinear: Fast and good for smaller datasets\n",
    "        # saga: Better for larger datasets\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "\n",
    "    #Fix the imbalance problem\n",
    "        # None: Treat hits and non-hits equally\n",
    "        # 'balanced': Force the model to care about hits\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "# Test the best combo of settings\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=42, max_iter=2000),\n",
    "                           param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation ROC-AUC score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414e8bf",
   "metadata": {},
   "source": [
    "### Train model with the current best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"\\nCross-validation ROC-AUC scores: {cv_scores}\")\n",
    "print(f\"Mean CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea8c68",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb68be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Non-Hit', 'Hit']))\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61187fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Hit', 'Hit'], yticklabels=['Non-Hit', 'Hit'])\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate additional metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(f\"\\nSpecificity (True Negative Rate): {specificity:.4f}\")\n",
    "print(f\"Sensitivity (True Positive Rate/Recall): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841006d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, \n",
    "         label=f'Precision-Recall curve (AP = {avg_precision:.4f})')\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower left\", fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88ae5e",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e97044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and visualize feature coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Coefficient': best_model.coef_[0]\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['green' if x > 0 else 'red' for x in feature_importance['Coefficient']]\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors)\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.title('Feature Importance (Logistic Regression Coefficients)', fontsize=16, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.grid(alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f449bf6f",
   "metadata": {},
   "source": [
    "This graph shows that tempo, loudness, acousticness, valence x energy, energy, and danceability are the most important features that people tend to grasp and increase replay value for a song, making it more likely to be a hit. (Music is subjective, however, but in general, these are the found audio features that people tend to gravitate towards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52182d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret coefficients (odds ratios)\n",
    "odds_ratios = np.exp(feature_importance['Coefficient'])\n",
    "feature_importance['Odds Ratio'] = odds_ratios\n",
    "feature_importance['Impact'] = feature_importance['Coefficient'].apply(\n",
    "    lambda x: 'Positive' if x > 0 else 'Negative'\n",
    ")\n",
    "\n",
    "print(\"\\nFeature Interpretation (Odds Ratios):\")\n",
    "print(feature_importance[['Feature', 'Coefficient', 'Odds Ratio', 'Impact']])\n",
    "print(\"\\nInterpretation: An odds ratio > 1 means the feature increases the likelihood of a hit.\")\n",
    "print(\"An odds ratio < 1 means the feature decreases the likelihood of a hit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac4dc2",
   "metadata": {},
   "source": [
    "## 8. Prediction Examples and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to predict hit probability for new songs\n",
    "def predict_hit_probability(song_features):\n",
    "    \"\"\"\n",
    "    Predict the probability that a song will be a hit.\n",
    "    \n",
    "    Parameters:\n",
    "    song_features: dict with audio features\n",
    "    \n",
    "    Returns:\n",
    "    probability of being a hit\n",
    "    \"\"\"\n",
    "    # Create DataFrame from input\n",
    "    song_df = pd.DataFrame([song_features])\n",
    "    \n",
    "    # Add engineered features\n",
    "    song_df['energy_danceability'] = song_df['energy'] * song_df['danceability']\n",
    "    song_df['valence_energy'] = song_df['valence'] * song_df['energy']\n",
    "    song_df['tempo_normalized'] = (song_df['tempo'] - df['tempo'].min()) / (df['tempo'].max() - df['tempo'].min())\n",
    "    song_df['mood_score'] = (song_df['valence'] + song_df['energy']) / 2\n",
    "    \n",
    "    # Scale features\n",
    "    song_scaled = scaler.transform(song_df[feature_columns])\n",
    "    \n",
    "    # Predict\n",
    "    probability = best_model.predict_proba(song_scaled)[0, 1]\n",
    "    \n",
    "    return probability\n",
    "\n",
    "# Example prediction\n",
    "example_song = {\n",
    "    'danceability': 0.95,\n",
    "    'energy': 0.90,\n",
    "    'valence': 0.45,\n",
    "    'tempo': 155,\n",
    "    'acousticness': 0.80,\n",
    "    'instrumentalness': 0.1,\n",
    "    'liveness': 0.15,\n",
    "    'speechiness': 0.05,\n",
    "    'loudness': 9.0\n",
    "}\n",
    "\n",
    "hit_prob = predict_hit_probability(example_song)\n",
    "print(f\"Example Song's Hit Probability: {hit_prob:.2%}\")\n",
    "print(f\"Prediction: {'A Hit :)' if hit_prob > 0.5 else 'Not a Hit :('}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassifications to gain insights\n",
    "test_results = X_test.copy()\n",
    "test_results['actual'] = y_test.values\n",
    "test_results['predicted'] = y_pred\n",
    "test_results['probability'] = y_pred_proba\n",
    "\n",
    "# False positives (predicted hit, actually not)\n",
    "false_positives = test_results[(test_results['actual'] == 0) & (test_results['predicted'] == 1)]\n",
    "print(f\"\\nFalse Positives Analysis (n={len(false_positives)}):\")\n",
    "print(false_positives[['danceability', 'energy', 'valence', 'probability']].describe())\n",
    "\n",
    "# False negatives (predicted not hit, actually is)\n",
    "false_negatives = test_results[(test_results['actual'] == 1) & (test_results['predicted'] == 0)]\n",
    "print(f\"\\nFalse Negatives Analysis (n={len(false_negatives)}):\")\n",
    "print(false_negatives[['danceability', 'energy', 'valence', 'probability']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28048ac9",
   "metadata": {},
   "source": [
    "## 9. Key Insights and Business Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for hits vs non-hits\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY INSIGHTS FROM THE MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. MODEL PERFORMANCE:\")\n",
    "print(f\"   - ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"   - Accuracy: {best_model.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"   - The model can effectively distinguish between hits and non-hits\")\n",
    "\n",
    "print(\"\\n2. TOP FEATURES THAT PREDICT HITS:\")\n",
    "top_positive = feature_importance.nlargest(3, 'Coefficient')\n",
    "for idx, row in top_positive.iterrows():\n",
    "    print(f\"   - {row['Feature']}: {row['Coefficient']:.4f} (OR: {row['Odds Ratio']:.4f})\")\n",
    "\n",
    "print(\"\\n3. FEATURES THAT DECREASE HIT PROBABILITY:\")\n",
    "top_negative = feature_importance.nsmallest(3, 'Coefficient')\n",
    "for idx, row in top_negative.iterrows():\n",
    "    print(f\"   - {row['Feature']}: {row['Coefficient']:.4f} (OR: {row['Odds Ratio']:.4f})\")\n",
    "\n",
    "print(\"\\n4. RECOMMENDATIONS FOR SPOTIFY:\")\n",
    "print(\"   - Focus on promoting songs with high danceability and energy\")\n",
    "print(\"   - The 'mood' of a song (combination of valence and energy) is crucial\")\n",
    "print(\"   - Songs with extreme instrumentalness or acousticness may need targeted marketing\")\n",
    "print(\"   - Consider these features in playlist curation algorithms\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313fe6f",
   "metadata": {},
   "source": [
    "## 10. Model Limitations and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a35c83",
   "metadata": {},
   "source": [
    "### Limitations:\n",
    "1. **Temporal bias**: The model doesn't account for changing music trends over time\n",
    "2. **External factors**: Marketing budget, artist popularity, and playlist placement aren't included\n",
    "3. **Genre specificity**: Different genres may have different success patterns\n",
    "4. **Definition of 'hit'**: Using popularity threshold is somewhat arbitrary\n",
    "\n",
    "### Possible Future Improvements:\n",
    "1. **Time-series analysis**: Incorporate release date and trend analysis\n",
    "2. **Genre-specific models**: Build separate models for different genres\n",
    "3. **Ensemble methods**: Combine logistic regression with tree-based models\n",
    "4. **Additional features**: Include artist features, label information, social media metrics\n",
    "5. **Multi-class classification**: Predict levels of success (flop, moderate, hit, mega-hit)\n",
    "6. **A/B testing framework**: Test model predictions against actual playlist performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
