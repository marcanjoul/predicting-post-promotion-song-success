{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37757345",
   "metadata": {},
   "source": [
    "# Hit Song Predictor: A Logistic Regression Approach\n",
    "\n",
    "## Project Overview\n",
    "This project uses logistic regression to predict whether a song will be a 'hit' based on audio features like danceability, energy, valence, and tempo. The model analyzes patterns in successful tracks to identify what makes a song popular.\n",
    "\n",
    "**Key Skills Demonstrated:**\n",
    "- Binary classification with logistic regression\n",
    "- Feature engineering and selection\n",
    "- Handling imbalanced datasets\n",
    "- Model evaluation and interpretation\n",
    "- Data visualization for music analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72470d34",
   "metadata": {},
   "source": [
    "### Import Necessary Tools & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248620fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70395d84",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eedb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"songs_normalize.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9bb4c",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab7019",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ebd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nBasic Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe23944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what makes a 'hit' - songs with popularity > 70\n",
    "# Adjust this threshold based on dataset\n",
    "popularity_threshold = df['popularity'].quantile(0.75)\n",
    "df['is_a_hit'] = (df['popularity'] > popularity_threshold).astype(int)\n",
    "\n",
    "print(f\"Popularity threshold for 'hit': {popularity_threshold}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['is_a_hit'].value_counts())\n",
    "print(f\"\\nHit rate: {df['is_a_hit'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ea8f1",
   "metadata": {},
   "source": [
    "### Visualize audio feature distributions for hits vs non-hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e771d",
   "metadata": {},
   "source": [
    "#### The Visualization shows\n",
    "Expected Strong Features:\n",
    "\n",
    "- Danceability ⭐⭐⭐\n",
    "- Energy ⭐⭐⭐\n",
    "- Valence ⭐⭐\n",
    "\n",
    "Expected Weak Features:\n",
    "\n",
    "- Tempo, Acousticness, Instrumentalness, Liveness, Speechiness, and Loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = ['danceability', 'energy', 'valence', 'tempo', 'acousticness', \n",
    "                  'instrumentalness', 'liveness', 'speechiness', 'loudness']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(audio_features):\n",
    "    axes[idx].hist(df[df['is_a_hit']==1][feature], alpha=0.5, label='Hit', bins=30, color='green')\n",
    "    axes[idx].hist(df[df['is_a_hit']==0][feature], alpha=0.5, label='Not a Hit', bins=30, color='red')\n",
    "    axes[idx].set_title(f'{feature.capitalize()} Distribution')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b03f9",
   "metadata": {},
   "source": [
    "### Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e599170",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df[audio_features + ['is_a_hit']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', square=True, linewidths=1)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1720781",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "The correlation heatmap reveals an that no individual audio feature shows string correlation with hit status (as expected since music is subjective, and there are many factors that go into having a hit, such as marketing, artist's popularity, timing, and cultureal context). The strongest correlations are:\n",
    "\n",
    "- Danceability: -0.02\n",
    "- Energy: -0.07  \n",
    "- Valence: -0.09\n",
    "- Acousticness: 0.07\n",
    "- All other features: ≈ 0.00\n",
    "\n",
    "### My Solution: Feature Engineering\n",
    "\n",
    "Since individual features lack predictive power, I will create interaction features that combine multiple attributes:\n",
    "\n",
    "1. **Energy × Danceability**: Captures the \"party factor\" - songs that are both energetic & danceable\n",
    "2. **Valence × Energy**: Represents upbeat, positive vibes\n",
    "3. **Mood Score**: Average of valence and energy for overall emotional tone\n",
    "4. **Normalized Tempo**: Standardized BPM for better model scaling\n",
    "\n",
    "**Hypothesis**: These engineered features will capture the non-linear relationships and feature combinations that differentiate hits from non-hits, where individual features alone cannot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e4f00",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee369d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['energy_danceability'] = df['energy'] * df['danceability']\n",
    "df['valence_energy'] = df['valence'] * df['energy']\n",
    "\n",
    "# Normalize tempo (convert BPM to a 0-1 scale)\n",
    "df['tempo_normalized'] = (df['tempo'] - df['tempo'].min()) / (df['tempo'].max() - df['tempo'].min())\n",
    "\n",
    "# Create a 'mood' feature combining valence and energy\n",
    "df['mood_score'] = (df['valence'] + df['energy']) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291c4ec",
   "metadata": {},
   "source": [
    "### Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "feature_columns = ['danceability', 'energy', 'valence', 'tempo_normalized', \n",
    "                   'acousticness', 'instrumentalness', 'liveness', 'speechiness', \n",
    "                   'loudness', 'energy_danceability', 'valence_energy', 'mood_score']\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['is_a_hit']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                      random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df275a87",
   "metadata": {},
   "source": [
    "### Standardizing Features for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94032d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier interpretation\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde00381",
   "metadata": {},
   "source": [
    "### Train Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "baseline_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "baseline_score = baseline_model.score(X_test_scaled, y_test)\n",
    "print(f\"Baseline Model Accuracy: {baseline_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b308d",
   "metadata": {},
   "source": [
    "### Hyperparameter Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GridSearchCV (Test all possible combinations of settings and pick the best one)\n",
    "param_grid = {\n",
    "    # How much the model will trust the data: \n",
    "        # 0.001 [Don't Trust data too much] \n",
    "        # 100   [Trust the data and get every detail]\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "\n",
    "    # How to simplify the model:\n",
    "        # L1: turn off uselss features completely\n",
    "        # L2: Make all features contribute a little bit \n",
    "    'penalty': ['l1', 'l2'], \n",
    "\n",
    "    #Which algorithm trains the model?\n",
    "        # liblinear: Fast and good for smaller datasets\n",
    "        # saga: Better for larger datasets\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "\n",
    "    #Fix the imbalance problem\n",
    "        # None: Treat hits and non-hits equally\n",
    "        # 'balanced': Force the model to care about hits\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "# Test the best combo of settings\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=42, max_iter=2000),\n",
    "                           param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation ROC-AUC score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998c4dd",
   "metadata": {},
   "source": [
    "### Model Performance Analysis\n",
    "\n",
    "**Results:**\n",
    "- ROC-AUC Score: 0.5942\n",
    "- Best Parameters: C=1, penalty='l2', solver='liblinear', class_weight=None\n",
    "\n",
    "**Score Interpretation:**\n",
    "- 0.50 = Random guessing\n",
    "- 0.59 = Our model (barely better than random)\n",
    "- 0.70+ = Acceptable\n",
    "- 0.80+ = Good\n",
    "\n",
    "#### Why Performance is Low\n",
    "\n",
    "This aligns with our correlation analysis showing no individual audio feature strongly predicts hits (all correlations < 0.10). \n",
    "\n",
    "**Key factors:**\n",
    "- Audio features alone are insufficient—commercial success depends on artist popularity, marketing budget, playlist placement, and timing\n",
    "- Linear model may miss non-linear patterns in the data\n",
    "- Interaction features may not capture complex relationships\n",
    "\n",
    "#### Cross-Validation Check\n",
    "```\n",
    "Scores: [0.623, 0.569, 0.572, 0.560, 0.647]\n",
    "Mean: 0.5942 ± 0.0687\n",
    "```\n",
    "\n",
    "Moderate variance across folds confirms the model is stable but consistently weak due to limited predictive power of audio features.\n",
    "\n",
    "#### Key Takeaway\n",
    "\n",
    "Audio characteristics alone cannot reliably predict hit songs—success depends more on marketing, artist popularity, and timing. This finding is valuable for understanding the limits of audio-based recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414e8bf",
   "metadata": {},
   "source": [
    "### Train model with the current best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"\\nCross-validation ROC-AUC scores: {cv_scores}\")\n",
    "print(f\"Mean CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a7675",
   "metadata": {},
   "source": [
    "## Cross-Validation Consistency Check\n",
    "\n",
    "To ensure our model's performance is reliable and not due to a lucky/unlucky train-test split, we performed 5-fold cross-validation.\n",
    "\n",
    "**Results:**\n",
    "```\n",
    "Cross-validation ROC-AUC scores: [0.623, 0.569, 0.572, 0.560, 0.647]\n",
    "Mean CV ROC-AUC: 0.5942 ± 0.0687\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "The scores show **moderate variance** across folds, ranging from 0.560 to 0.647. This indicates:\n",
    "\n",
    "1. **Model performance is somewhat dependent on the data split** - with a relatively small dataset (1,600 training samples), different folds capture slightly different patterns\n",
    "\n",
    "2. **The best fold (0.647) shows marginal predictive ability** - this suggests there is *some* signal in the audio features, but it's weak and inconsistent\n",
    "\n",
    "3. **Standard deviation of ±0.069 is acceptable** for a dataset of this size, indicating the model isn't wildly unstable, just working with limited predictive features\n",
    "\n",
    "**Key Takeaway:** The consistency of low scores across all folds confirms that the weak performance is due to **insufficient predictive power of audio features**, not model instability or a poor train-test split. This reinforces our earlier finding that commercial success depends more on non-audio factors (marketing, artist popularity, timing) than on audio characteristics alone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
